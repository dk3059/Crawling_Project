{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 크롤링 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 수집 동기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./picture/word_count.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![0](./picture/mask1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 크롤링하는 방법 - 스크래피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 프로젝트 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Items 설정\n",
    "#### gmarket\n",
    "```Python\n",
    "class GmarketItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    s_price = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "  \n",
    "```\n",
    "####  naver\n",
    "```python\n",
    "class NaverNewsItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    link = scrapy.Field()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. spider 작성\n",
    "#### gmarket\n",
    "```Python\n",
    "class GmarketSpider(scrapy.Spider):\n",
    "    name = \"gmarket\"\n",
    "    allow_domain = [\"http://www.gmarket.co.kr\"]\n",
    "    start_urls = [\"http://corners.gmarket.co.kr/Bestsellers?viewType=G&groupCode=G08\"] #living 카테고리에서 시작\n",
    "    \n",
    "    def parse(self, response):\n",
    "        items = response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')\n",
    "        for item in items:\n",
    "            link = item.xpath(\"./a/@href\").extract()[0] #괄호 없애줌\n",
    "            yield scrapy.Request(link, callback=self.parse_page_contents)\n",
    "            \n",
    "    def parse_page_contents(self, response):\n",
    "        item = GmarketItem()\n",
    "        item[\"title\"] = response.xpath('//*[@id=\"itemcase_basic\"]/h1/text()').extract()[0].strip()\n",
    "        s_price = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong/text()').extract()\n",
    "        item[\"s_price\"] = [item.replace(\",\", \"\") for item in s_price][0] #개당 가격을 계산하기 위해 , 제거\n",
    "        item[\"link\"] = response.url\n",
    "        yield item\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naver\n",
    "\n",
    "```python\n",
    "class Spider(scrapy.Spider):\n",
    "    name = \"NaverNews\"\n",
    "    allow_domain = [\"naver.com\"]\n",
    "    start_urls = [\"https://news.naver.com/main/home.nhn\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = NaverNewsItem()\n",
    "        link_p = response.xpath('//*[@id=\"section_politics\"]/div[2]/div/ul/li/a/@href').extract() #정치\n",
    "        link_e = response.xpath('//*[@id=\"section_economy\"]/div[2]/div/ul/li/a/@href').extract() #경제\n",
    "        link_s = response.xpath('//*[@id=\"section_society\"]/div[2]/div/ul/li/a/@href').extract() #사회\n",
    "        urls = response.xpath('//*[@id=\"today_main_news\"]/div[2]/ul/li/div[1]/a/@href').extract() #헤드라인\n",
    "        \n",
    "        link_h = []\n",
    "        for url in urls:\n",
    "            link_h.append(response.urljoin(url)) #start_urls과 헤드라인 join\n",
    "            \n",
    "        links = link_p + link_e + link_s + link_h #링크 합치기\n",
    "        \n",
    "        for link in links:\n",
    "            yield scrapy.Request(link, callback=self.page_content)\n",
    "            \n",
    "    def page_content(self, response):\n",
    "        item = NaverNewsItem()\n",
    "        item[\"title\"] = response.xpath('//*[@id=\"articleTitle\"]/text()')[0].extract()\n",
    "        item[\"link\"] = response.url\n",
    "\n",
    "        yield item\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. pipeline 설정하기\n",
    "\n",
    "#### gmarket\n",
    "1. slack으로 이름, 단위당 가격, 판매가격, 링크 보내기\n",
    "\n",
    "```python\n",
    "class CrawlerPipeline(object):\n",
    "    \n",
    "    def __send_slack(self, msg):\n",
    "        WEBHOOK_URL = \"https://hooks.slack.com/services/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\"\n",
    "        payload = {\n",
    "            \"channel\" : \"#dk3059\",\n",
    "            \"username\" : \"KDK\",\n",
    "            \"icon_emoji\" : \":crn:\",\n",
    "            \"text\" : msg,\n",
    "        }\n",
    "        requests.post(WEBHOOK_URL, json.dumps(payload))\n",
    "    \n",
    "    \n",
    "    def process_item(self, item, spider):\n",
    "        keyword = \"마스크\"\n",
    "\n",
    "        if keyword in item[\"title\"]:\n",
    "            try : \n",
    "                num = re.findall('\\s([0-9]{2,3})\\S.', item[\"title\"])[0] #정규표현식을 사용하여 이름에서 단위 추출\n",
    "                \n",
    "            except:\n",
    "                num = 1\n",
    "            \n",
    "            num_p = round((int(item['s_price'])/int(num))) #개당 가격\n",
    "            \n",
    "            if num_p < 4000: #개당 가격이 4000원 미만일 때 슬렉으로 보내기\n",
    "                \n",
    "                print(item['title'])\n",
    "                self.__send_slack(\"*{}*, {}, `{}`, {}, {}\".format( \n",
    "                \"gmarket\", item['title'], num_p, item['s_price'], item['link'])) #gmarket, 개당 가격 강조 \n",
    "           \n",
    "        return item\n",
    "```\n",
    "\n",
    "\n",
    "2. mongodb에 데이터 저장하기\n",
    "\n",
    "```python\n",
    "class CrawlerPipeline2(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \n",
    "        data = {\"title\" : item[\"title\"],\n",
    "                \"s_price\" : item[\"s_price\"],\n",
    "                \"link\" : item[\"link\"]}\n",
    "        \n",
    "        collection.insert(data)\n",
    "        \n",
    "        return item\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naver\n",
    "1. slack으로 기사 제목, url 보내기\n",
    "\n",
    "```python\n",
    "class CrawlerPipeline(object):\n",
    "    \n",
    "    def __send_slack(self, msg):\n",
    "        WEBHOOK_URL = \"https://hooks.slack.com/services/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\"\n",
    "        payload = {\n",
    "            \"channel\" : \"#dk3059\",\n",
    "            \"username\" : \"KDK\",\n",
    "            \"text\" : msg,\n",
    "        }\n",
    "        requests.post(WEBHOOK_URL, json.dumps(payload))\n",
    "\n",
    "        \n",
    "    \n",
    "    def process_item(self, item, spider):\n",
    "        keyword = \"코로나\"\n",
    "        keyword2 = \"마스크\"\n",
    "        if keyword in item[\"title\"] or keyword2 in item[\"title\"]:\n",
    "            self.__send_slack(\"*{}*, {}\".format(item['title'], item['link'])) #코로나, 마스크가 포함된 기사제목만 볼드체\n",
    "        else :\n",
    "            self.__send_slack(\"{}, {}\".format(item['title'], item['link']))\n",
    "        return item\n",
    "```\n",
    "2. mongodb에 저장하기\n",
    "\n",
    "```python\n",
    "class CrawlerPipeline2(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \n",
    "        data = {\"title\" : item[\"title\"],\n",
    "                \"link\" : item[\"link\"]}\n",
    "        \n",
    "        collection.insert(data)\n",
    "        return item\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gmarket\n",
    "\n",
    "```python\n",
    "!echo \"ITEM_PIPELINES = {\" >> gmarket_living/gmarket_living/settings.py\n",
    "!echo \"    'gmarket_living.pipelines.CrawlerPipeline' : 300,\" >> gmarket_living/gmarket_living/settings.py\n",
    "!echo \"    'gmarket_living.pipelines.CrawlerPipeline2' : 301,\" >> gmarket_living/gmarket_living/settings.py\n",
    "!echo \"}\" >> gmarket_living/gmarket_living/settings.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. scrapy 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 슬랙\n",
    "<img src=\"./picture/slack.png\">\n",
    "<img src=\"./picture/slack_n.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. mongodb\n",
    "\n",
    "<img src=\"./picture/robo_n.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coupang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%writefile coupang.py\n",
    "from pyvirtualdisplay import Display \n",
    "from selenium import webdriver \n",
    "import pandas as pd\n",
    "import re\n",
    "import pymongo\n",
    "\n",
    "class coupang():\n",
    "\n",
    "    def __init__(self, keyword):\n",
    "        self.data = {}\n",
    "        self.get_links(keyword)\n",
    "        self.mongo()\n",
    "        \n",
    "    def get_links(self, keyword):\n",
    "        datas = []\n",
    "        url = \"https://www.coupang.com/np/search?q={}&channel=recent\".format(keyword)\n",
    "        display = Display(visible=0, size=(800, 600)) \n",
    "        display.start() \n",
    "        driver = webdriver.Chrome() \n",
    "        driver.get(url) \n",
    "        elements = driver.find_elements_by_xpath('//*[@id=\"productList\"]/li/a')\n",
    "        links = [element.get_attribute(\"href\") for element in elements]\n",
    "        driver.quit()\n",
    "        display.stop()\n",
    "        for link in links:\n",
    "            display = Display(visible=0, size=(800, 600)) \n",
    "            display.start() \n",
    "            driver = webdriver.Chrome() \n",
    "            driver.get(link) \n",
    "            elements = driver.find_elements_by_xpath('//*[@id=\"contents\"]/div[1]/div/div[3]/div[3]/h2')\n",
    "            title = [element.text for element in elements][0]\n",
    "            elements1 = driver.find_elements_by_xpath('//*[@id=\"contents\"]/div[1]/div/div[3]/div[5]/div[1]/div/div[2]/span[1]/strong')\n",
    "            try:\n",
    "                s_price = [element.text.replace(\",\", \"\")[:-1] for element in elements1][0] #품절인 경우\n",
    "            except :\n",
    "                s_price = 0\n",
    "            elements2 = driver.find_elements_by_xpath('//*[@id=\"contents\"]/div[1]/div/div[3]/div[6]/div[2]/div/div[1]/div[1]/span')\n",
    "            d_price = [element.text.replace(\",\", \"\") for element in elements2][0]\n",
    "            if re.findall('\\s([0-9]{4,6})\\S+', d_price):\n",
    "                d_price = re.findall('\\s([0-9]{4,6})\\S+', d_price)[0] #배송비만 가져옴\n",
    "            else :\n",
    "                d_price = 0\n",
    "            price = int(s_price) + int(d_price) #배송가격과 판매가격을 더해줌\n",
    "            datas.append({\"title\" : title, \"price\" : price, \"link\" : link})\n",
    "            driver.quit()\n",
    "            display.stop()\n",
    "        self.data = datas\n",
    "    \n",
    "\n",
    "    def mongo(self): #mongodb에 저장\n",
    "        client = pymongo.MongoClient('mongodb://15.165.218.144:27017/')\n",
    "        db = client.coupang\n",
    "        collection = db.mask\n",
    "        collection.insert(self.data)\n",
    "        \n",
    "coupang(\"마스크\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./delivery.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./picture/pd_coupang.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mongodb 저장 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./picture/robo3_coupang.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 프레임 가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 데이터 프레임 불러오기\n",
    "```python\n",
    "client = pymongo.MongoClient('mongodb://15.165.218.144:27017/')\n",
    "db = client.coupang\n",
    "collection = db.mask\n",
    "items = collection.find({})\n",
    "df = pd.DataFrame(items)\n",
    "df = df[['title', 'price']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터 전처리\n",
    "1. 제목에 단위 추출하기\n",
    "\n",
    "```python\n",
    "df['unit'] = df['title'].apply(lambda data : int(re.findall('\\s([0-9]{2,3})\\S+', data)[0]) if re.findall('\\s([0-9]{2,3})\\S+', data) else 1)\n",
    "```\n",
    "\n",
    "2. 단위당 가격 추출하기\n",
    "\n",
    "```python\n",
    "df['u_price'] = round(df['price'] / df['unit'])\n",
    "df['n_price'] =df['u_price'].apply(lambda x : 500 if 0<x<1000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 1000 if 1000<x<2000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 2000 if 2000<x<3000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 3000 if 3000<x<4000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 4000 if 4000<x<5000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 5000 if 5000<x<6000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 6000 if 6000<x<7000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 7000 if 7000<x<8000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 8000 if 8000<x<9000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 9000 if 9000<x<10000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 10000 if 10000<x<20000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 20000 if 20000<x<30000 else x)\n",
    "df['n_price'] =df['n_price'].apply(lambda x : 30000 if 30000<x else x)\n",
    "```\n",
    "\n",
    "3. KF인지 아닌지 확인\n",
    "\n",
    "```python\n",
    "df['KF'] = df['title'].apply(lambda data : 1 if re.findall('([K,F,N]{2})', data) else 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 프레임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./picture/df.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KF와 일회용 마스크의 가격비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Total\n",
    "<img src=\"./picture/Total.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.KF, KN\n",
    "<img src=\"./picture/KF.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 일회용\n",
    "<img src=\"./picture/n_KF.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 프로젝트 회고\n",
    " - 차후 주기적으로 크롤링을 통해 마스크5부제나 추우 정부 정책의 성공여부를 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
